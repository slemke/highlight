<html !DOCTYPE>
    <head>
        <title>Output</title>
        <style>
            body {
                font-family: Arial;
                font-size: 14px;
                padding: 0;
                margin: 0;
                background-color: #f5f5f5;
            }

            #text {
                max-width: 690px;
                padding: 1rem;
                margin: 0 auto;
                line-height: 1.4rem;
                background-color: #FFF;
                border-left: 1px solid #efefef;
                border-right: 1px solid #efefef;
                box-shadow: 0px 0px 4px #efefef;
                color: #b3b3b3;
            }

            .highlight {
                color: #03a9f4;
            }
        </style>
    </head>
    <body>
        <div id="text">
            <span> 
Structuring Your Project¶

By “structure” we mean the decisions you make concerning
how your project best meets its objective.</span><span> We need to consider how to
best leverage Python’s features to create clean, effective code.</span><span class="highlight"> In practical terms, “structure” means making clean code whose logic and
dependencies are clear as well as how the files and folders are organized
in the filesystem.</span><span> Which functions should go into which modules?</span><span> How does data flow through
the project?</span><span> What features and functions can be grouped together and
isolated?</span><span class="highlight"> By answering questions like these you can begin to plan, in
a broad sense, what your finished product will look like.</span><span class="highlight"> In this section we take a closer look at Python’s module and import
systems as they are the central elements to enforcing structure in your
project.</span><span> We then discuss various perspectives on how to build code which
can be extended and tested reliably.</span><span class="highlight"> Structure of the Repository¶

It’s Important.¶
Just as Code Style, API Design, and Automation are essential for a
healthy development cycle, Repository structure is a crucial part of
your project’s
architecture.</span><span class="highlight"> When a potential user or contributor lands on your repository’s page,
they see a few things:

Project Name
Project Description
Bunch O’ Files

Only when they scroll below the fold will the user see your project’s
README.</span><span class="highlight"> If your repo is a massive dump of files or a nested mess of directories,
they might look elsewhere before even reading your beautiful
documentation.</span><span class="highlight"> Dress for the job you want, not the job you have.</span><span> Of course, first impressions aren’t everything.</span><span> You and your colleagues
will spend countless hours working with this repository, eventually
becoming intimately familiar with every nook and cranny.</span><span> The layout of
it is important.</span><span> Sample Repository¶
tl;dr: This is what Kenneth Reitz recommended in 2013&lt;https://www.kennethreitz.org/essays/repository-structure-and-python&gt;.</span><span> This repository is available on
GitHub.</span><span> README.rst
LICENSE
setup.py
requirements.txt
sample/__init__.py
sample/core.py
sample/helpers.py
docs/conf.py
docs/index.rst
tests/test_basic.py
tests/test_advanced.py


Let’s get into some specifics.</span><span class="highlight"> The Actual Module¶






Location
./sample/ or ./sample.py

Purpose
The code of interest



Your module package is the core focus of the repository.</span><span class="highlight"> It should not
be tucked away:
./sample/


If your module consists of only a single file, you can place it directly
in the root of your repository:
./sample.py


Your library does not belong in an ambiguous src or python subdirectory.</span><span> License¶






Location
./LICENSE

Purpose
Lawyering up.</span><span class="highlight"> This is arguably the most important part of your repository, aside from
the source code itself.</span><span> The full license text and copyright claims
should exist in this file.</span><span> If you aren’t sure which license you should use for your project, check
out choosealicense.com.</span><span class="highlight"> Of course, you are also free to publish code without a license, but this
would prevent many people from potentially using your code.</span><span> Setup.py¶






Location
./setup.py

Purpose
Package and distribution management.</span><span class="highlight"> If your module package is at the root of your repository, this should
obviously be at the root as well.</span><span> Requirements File¶






Location
./requirements.txt

Purpose
Development dependencies.</span><span> A pip requirements
file
should be placed at the root of the repository.</span><span class="highlight"> It should specify the
dependencies required to contribute to the project: testing, building,
and generating documentation.</span><span> If your project has no development dependencies, or you prefer
development environment setup via setup.py, this file may be
unnecessary.</span><span> Documentation¶






Location
./docs/

Purpose
Package reference documentation.</span><span> There is little reason for this to exist elsewhere.</span><span> Test Suite¶
For advice on writing your tests, see Testing Your Code.</span><span> Location
./test_sample.py or ./tests

Purpose
Package integration and unit tests.</span><span class="highlight"> Starting out, a small test suite will often exist in a single file:
./test_sample.py


Once a test suite grows, you can move your tests to a directory, like
so:
tests/test_basic.py
tests/test_advanced.py


Obviously, these test modules must import your packaged module to test
it.</span><span> You can do this a few ways:

Expect the package to be installed in site-packages.</span><span> Use a simple (but explicit) path modification to resolve the
package properly.</span><span> I highly recommend the latter.</span><span class="highlight"> Requiring a developer to run
setup.py develop to test an actively changing
codebase also requires them to have an isolated environment setup for
each instance of the codebase.</span><span class="highlight"> To give the individual tests import context, create a tests/context.py
file:
import os
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), &#x27;..&#x27;)))

import sample


Then, within the individual test modules, import the module like so:
from .context import sample


This will always work as expected, regardless of installation method.</span><span> Some people will assert that you should distribute your tests within
your module itself – I disagree.</span><span> It often increases complexity for your
users; many test suites often require additional dependencies and
runtime contexts.</span><span> Makefile¶






Location
./Makefile

Purpose
Generic management tasks.</span><span> If you look at most of my projects or any Pocoo project, you’ll notice a
Makefile lying around.</span><span> Why?</span><span> These projects aren’t written in C… In
short, make is an incredibly useful tool for defining generic tasks for
your project.</span><span> Sample Makefile:
init:
    pip install -r requirements.txt

test:
    py.test tests

.PHONY: init test


Other generic management scripts (e.g.</span><span> manage.py
or fabfile.py) belong at the root of the repository as well.</span><span> Regarding Django Applications¶
I’ve noticed a new trend in Django applications since the release of
Django 1.4.</span><span> Many developers are structuring their repositories poorly
due to the new bundled application templates.</span><span> How?</span><span class="highlight"> Well, they go to their bare and fresh repository and run the
following, as they always have:
$ django-admin.py startproject samplesite


The resulting repository structure looks like this:
README.rst
samplesite/manage.py
samplesite/samplesite/settings.py
samplesite/samplesite/wsgi.py
samplesite/samplesite/sampleapp/models.py


Don’t do this.</span><span> Repetitive paths are confusing for both your tools and your developers.</span><span> Unnecessary nesting doesn’t help anybody (unless they’re nostalgic for
monolithic SVN repos).</span><span> Let’s do it properly:
$ django-admin.py startproject samplesite .</span><span> Note the “.”.</span><span class="highlight"> The resulting structure:
README.rst
manage.py
samplesite/settings.py
samplesite/wsgi.py
samplesite/sampleapp/models.py





Structure of Code is Key¶
Thanks to the way imports and modules are handled in Python, it is
relatively easy to structure a Python project.</span><span class="highlight"> Easy, here, means
that you do not have many constraints and that the module
importing model is easy to grasp.</span><span class="highlight"> Therefore, you are left with the
pure architectural task of crafting the different parts of your
project and their interactions.</span><span> Easy structuring of a project means it is also easy
to do it poorly.</span><span class="highlight"> Some signs of a poorly structured project
include:

Multiple and messy circular dependencies: if your classes
Table and Chair in furn.py need to import Carpenter from
workers.py to answer a question such as table.isdoneby(),
and if conversely the class Carpenter needs to import Table and Chair
to answer the question carpenter.whatdo(), then you
have a circular dependency.</span><span> In this case you will have to resort to
fragile hacks such as using import statements inside
methods or functions.</span><span class="highlight"> Hidden coupling: each and every change in Table’s implementation
breaks 20 tests in unrelated test cases because it breaks Carpenter’s code,
which requires very careful surgery to adapt the change.</span><span> This means
you have too many assumptions about Table in Carpenter’s code or the
reverse.</span><span class="highlight"> Heavy usage of global state or context: instead of explicitly
passing (height, width, type, wood) to each other, Table
and Carpenter rely on global variables that can be modified
and are modified on the fly by different agents.</span><span class="highlight"> You need to
scrutinize all access to these global variables to understand why
a rectangular table became a square, and discover that remote
template code is also modifying this context, messing with
table dimensions.</span><span class="highlight"> Spaghetti code: multiple pages of nested if clauses and for loops
with a lot of copy-pasted procedural code and no
proper segmentation are known as spaghetti code.</span><span> Python’s
meaningful indentation (one of its most controversial features) make
it very hard to maintain this kind of code.</span><span> So the good news is that
you might not see too much of it.</span><span class="highlight"> Ravioli code is more likely in Python: it consists of hundreds of
similar little pieces of logic, often classes or objects, without
proper structure.</span><span class="highlight"> If you never can remember if you have to use
FurnitureTable, AssetTable or Table, or even TableNew for your
task at hand, you might be swimming in ravioli code.</span><span> Modules¶
Python modules are one of the main abstraction layers available and probably the
most natural one.</span><span> Abstraction layers allow separating code into parts holding
related data and functionality.</span><span class="highlight"> For example, a layer of a project can handle interfacing with user actions,
while another would handle low-level manipulation of data.</span><span class="highlight"> The most natural way
to separate these two layers is to regroup all interfacing functionality
in one file, and all low-level operations in another file.</span><span class="highlight"> In this case,
the interface file needs to import the low-level file.</span><span> This is done with the
import and from ... import statements.</span><span> As soon as you use import statements you use modules.</span><span class="highlight"> These can be either
built-in modules such as os and sys, third-party modules you have installed
in your environment, or your project’s internal modules.</span><span class="highlight"> To keep in line with the style guide, keep module names short, lowercase, and
be sure to avoid using special symbols like the dot (.)</span><span> or question mark (?).</span><span> So a file name like my.spam.py is one you should avoid!</span><span> Naming this way
will interfere with the way Python looks for modules.</span><span class="highlight"> In the case of my.spam.py Python expects to find a spam.py file in a
folder named my which is not the case.</span><span class="highlight"> There is an
example of how the
dot notation should be used in the Python docs.</span><span class="highlight"> If you’d like you could name your module my_spam.py, but even our
friend the underscore should not be seen often in module names.</span><span class="highlight"> However, using other
characters (spaces or hyphens) in module names will prevent importing
(- is the subtract operator), so try to keep module names short so there is
no need to separate words.</span><span> And, most of all, don’t namespace with underscores; use submodules instead.</span><span class="highlight"> # OK
import library.plugin.foo
# not OK
import library.foo_plugin


Aside from some naming restrictions, nothing special is required for a Python
file to be a module, but you need to understand the import mechanism in order
to use this concept properly and avoid some issues.</span><span class="highlight"> Concretely, the import modu statement will look for the proper file, which
is modu.py in the same directory as the caller if it exists.</span><span class="highlight"> If it is
not found, the Python interpreter will search for modu.py in the “path”
recursively and raise an ImportError exception if it is not found.</span><span class="highlight"> Once modu.py is found, the Python interpreter will execute the module in
an isolated scope.</span><span> Any top-level statement in modu.py will be executed,
including other imports if any.</span><span> Function and class definitions are stored in
the module’s dictionary.</span><span class="highlight"> Then, the module’s variables, functions, and classes will be available to the
caller through the module’s namespace, a central concept in programming that is
particularly helpful and powerful in Python.</span><span class="highlight"> In many languages, an include file directive is used by the preprocessor to
take all code found in the file and ‘copy’ it into the caller’s code.</span><span class="highlight"> It is
different in Python: the included code is isolated in a module namespace, which
means that you generally don’t have to worry that the included code could have
unwanted effects, e.g.</span><span> override an existing function with the same name.</span><span class="highlight"> It is possible to simulate the more standard behavior by using a special syntax
of the import statement: from modu import *.</span><span> This is generally considered
bad practice.</span><span> Using import * makes code harder to read and makes
dependencies less compartmentalized.</span><span class="highlight"> Using from modu import func is a way to pinpoint the function you want to
import and put it in the local namespace.</span><span class="highlight"> While much less harmful than import
* because it shows explicitly what is imported in the local namespace, its
only advantage over a simpler import modu is that it will save a little
typing.</span><span> Very bad
[...]
from modu import *
[...]
x = sqrt(4)  # Is sqrt part of modu?</span><span> A builtin?</span><span> Defined above?</span><span class="highlight"> Better
from modu import sqrt
[...]
x = sqrt(4)  # sqrt may be part of modu, if not redefined in between


Best
import modu
[...]
x = modu.sqrt(4)  # sqrt is visibly part of modu&#x27;s namespace


As mentioned in the Code Style section, readability is one of the main
features of Python.</span><span> Readability means to avoid useless boilerplate text and
clutter; therefore some efforts are spent trying to achieve a certain level of
brevity.</span><span> But terseness and obscurity are the limits where brevity should stop.</span><span class="highlight"> Being able to tell immediately where a class or function comes from, as in the
modu.func idiom, greatly improves code readability and understandability in
all but the simplest single file projects.</span><span class="highlight"> Packages¶
Python provides a very straightforward packaging system, which is simply an
extension of the module mechanism to a directory.</span><span> Any directory with an __init__.py file is considered a Python package.</span><span class="highlight"> The different modules in the package are imported in a similar manner as plain
modules, but with a special behavior for the __init__.py file, which is
used to gather all package-wide definitions.</span><span> A file modu.py in the directory pack/ is imported with the
statement import pack.modu.</span><span> This statement will look for an
__init__.py file in pack and execute all of its top-level
statements.</span><span> Then it will look for a file named pack/modu.py and
execute all of its top-level statements.</span><span class="highlight"> After these operations, any variable,
function, or class defined in modu.py is available in the pack.modu
namespace.</span><span> A commonly seen issue is to add too much code to __init__.py
files.</span><span class="highlight"> When the project complexity grows, there may be sub-packages and
sub-sub-packages in a deep directory structure.</span><span class="highlight"> In this case, importing a
single item from a sub-sub-package will require executing all
__init__.py files met while traversing the tree.</span><span class="highlight"> Leaving an __init__.py file empty is considered normal and even a good
practice, if the package’s modules and sub-packages do not need to share any
code.</span><span> Lastly, a convenient syntax is available for importing deeply nested packages:
import very.deep.module as mod.</span><span> This allows you to use mod in place of the
verbose repetition of very.deep.module.</span><span> Object-oriented programming¶
Python is sometimes described as an object-oriented programming language.</span><span> This
can be somewhat misleading and needs to be clarified.</span><span class="highlight"> In Python, everything is an object, and can be handled as such.</span><span class="highlight"> This is what is
meant when we say, for example, that functions are first-class objects.</span><span class="highlight"> Functions, classes, strings, and even types are objects in Python: like any
object, they have a type, they can be passed as function arguments, and they
may have methods and properties.</span><span> In this understanding, Python is an
object-oriented language.</span><span> However, unlike Java, Python does not impose object-oriented programming as the
main programming paradigm.</span><span> It is perfectly viable for a Python project to not
be object-oriented, i.e.</span><span class="highlight"> to use no or very few class definitions, class
inheritance, or any other mechanisms that are specific to object-oriented
programming.</span><span class="highlight"> Moreover, as seen in the modules section, the way Python handles modules and
namespaces gives the developer a natural way to ensure the
encapsulation and separation of abstraction layers, both being the most common
reasons to use object-orientation.</span><span class="highlight"> Therefore, Python programmers have more
latitude to not use object-orientation, when it is not required by the business
model.</span><span> There are some reasons to avoid unnecessary object-orientation.</span><span> Defining
custom classes is useful when we want to glue together some state and some
functionality.</span><span class="highlight"> The problem, as pointed out by the discussions about functional
programming, comes from the “state” part of the equation.</span><span class="highlight"> In some architectures, typically web applications, multiple instances of Python
processes are spawned to respond to external requests that can happen at the
same time.</span><span class="highlight"> In this case, holding some state in instantiated objects, which
means keeping some static information about the world, is prone to concurrency
problems or race conditions.</span><span class="highlight"> Sometimes, between the initialization of the state
of an object (usually done with the __init__() method) and the actual use
of the object state through one of its methods, the world may have changed, and
the retained state may be outdated.</span><span> For example, a request may load an item in
memory and mark it as read by a user.</span><span class="highlight"> If another request requires the deletion
of this item at the same time, it may happen that the deletion actually occurs
after the first process loaded the item, and then we have to mark as read a
deleted object.</span><span> This and other issues led to the idea that using stateless functions is a
better programming paradigm.</span><span class="highlight"> Another way to say the same thing is to suggest using functions and procedures
with as few implicit contexts and side-effects as possible.</span><span class="highlight"> A function’s
implicit context is made up of any of the global variables or items in the
persistence layer that are accessed from within the function.</span><span> Side-effects are
the changes that a function makes to its implicit context.</span><span class="highlight"> If a function saves
or deletes data in a global variable or in the persistence layer, it is said to
have a side-effect.</span><span class="highlight"> Carefully isolating functions with context and side-effects from functions with
logic (called pure functions) allow the following benefits:

Pure functions are deterministic: given a fixed input,
the output will always be the same.</span><span> Pure functions are much easier to change or replace if they need to
be refactored or optimized.</span><span> Pure functions are easier to test with unit tests: There is less
need for complex context setup and data cleaning afterwards.</span><span> Pure functions are easier to manipulate, decorate, and pass around.</span><span> In summary, pure functions are more efficient building blocks than classes
and objects for some architectures because they have no context or side-effects.</span><span class="highlight"> Obviously, object-orientation is useful and even necessary in many cases, for
example when developing graphical desktop applications or games, where the
things that are manipulated (windows, buttons, avatars, vehicles) have a
relatively long life of their own in the computer’s memory.</span><span> Decorators¶
The Python language provides a simple yet powerful syntax called ‘decorators’.</span><span class="highlight"> A decorator is a function or a class that wraps (or decorates) a function
or a method.</span><span> The ‘decorated’ function or method will replace the original
‘undecorated’ function or method.</span><span class="highlight"> Because functions are first-class objects
in Python, this can be done ‘manually’, but using the @decorator syntax is
clearer and thus preferred.</span><span class="highlight"> def foo():
    # do something

def decorator(func):
    # manipulate func
    return func

foo = decorator(foo)  # Manually decorate

@decorator
def bar():
    # Do something
# bar() is decorated


This mechanism is useful for separating concerns and avoiding
external unrelated logic ‘polluting’ the core logic of the function
or method.</span><span class="highlight"> A good example of a piece of functionality that is better handled
with decoration is memoization or caching: you want to store the results of an
expensive function in a table and use them directly instead of recomputing
them when they have already been computed.</span><span> This is clearly not part
of the function logic.</span><span> Context Managers¶
A context manager is a Python object that provides extra contextual information
to an action.</span><span class="highlight"> This extra information takes the form of running a callable upon
initiating the context using the with statement, as well as running a callable
upon completing all the code inside the with block.</span><span class="highlight"> The most well known
example of using a context manager is shown here, opening on a file:
with open(&#x27;file.txt&#x27;) as f:
    contents = f.read()


Anyone familiar with this pattern knows that invoking open in this fashion
ensures that f’s close method will be called at some point.</span><span> This reduces
a developer’s cognitive load and makes the code easier to read.</span><span> There are two easy ways to implement this functionality yourself: using a class
or using a generator.</span><span class="highlight"> Let’s implement the above functionality ourselves, starting
with the class approach:
class CustomOpen(object):
    def __init__(self, filename):
        self.file = open(filename)

    def __enter__(self):
        return self.file

    def __exit__(self, ctx_type, ctx_value, ctx_traceback):
        self.file.close()

with CustomOpen(&#x27;file&#x27;) as f:
    contents = f.read()


This is just a regular Python object with two extra methods that are used
by the with statement.</span><span class="highlight"> CustomOpen is first instantiated and then its
__enter__ method is called and whatever __enter__ returns is assigned to
f in the as f part of the statement.</span><span class="highlight"> When the contents of the with block
is finished executing, the __exit__ method is then called.</span><span class="highlight"> And now the generator approach using Python’s own
contextlib:
from contextlib import contextmanager

@contextmanager
def custom_open(filename):
    f = open(filename)
    try:
        yield f
    finally:
        f.close()

with custom_open(&#x27;file&#x27;) as f:
    contents = f.read()


This works in exactly the same way as the class example above, albeit it’s
more terse.</span><span> The custom_open function executes until it reaches the yield
statement.</span><span class="highlight"> It then gives control back to the with statement, which assigns
whatever was yield’ed to f in the as f portion.</span><span> The finally clause
ensures that close() is called whether or not there was an exception inside
the with.</span><span class="highlight"> Since the two approaches appear the same, we should follow the Zen of Python
to decide when to use which.</span><span> The class approach might be better if there’s
a considerable amount of logic to encapsulate.</span><span> The function approach
might be better for situations where we’re dealing with a simple action.</span><span> Dynamic typing¶
Python is dynamically typed, which means that variables do not have a fixed
type.</span><span class="highlight"> In fact, in Python, variables are very different from what they are in
many other languages, specifically statically-typed languages.</span><span class="highlight"> Variables are not
a segment of the computer’s memory where some value is written, they are ‘tags’
or ‘names’ pointing to objects.</span><span class="highlight"> It is therefore possible for the variable ‘a’ to
be set to the value 1, then to the value ‘a string’, then to a function.</span><span class="highlight"> The dynamic typing of Python is often considered to be a weakness, and indeed
it can lead to complexities and hard-to-debug code.</span><span class="highlight"> Something named ‘a’ can be
set to many different things, and the developer or the maintainer needs to track
this name in the code to make sure it has not been set to a completely unrelated
object.</span><span> Some guidelines help to avoid this issue:

Avoid using the same variable name for different things.</span><span class="highlight"> Bad
a = 1
a = &#x27;a string&#x27;
def a():
    pass  # Do something


Good
count = 1
msg = &#x27;a string&#x27;
def func():
    pass  # Do something


Using short functions or methods helps reduce the risk
of using the same name for two unrelated things.</span><span class="highlight"> It is better to use different names even for things that are related,
when they have a different type:
Bad
items = &#x27;a b c d&#x27;  # This is a string...
items = items.split(&#x27; &#x27;)  # ...becoming a list
items = set(items)  # ...and then a set


There is no efficiency gain when reusing names: the assignments
will have to create new objects anyway.</span><span class="highlight"> However, when the complexity
grows and each assignment is separated by other lines of code, including
‘if’ branches and loops, it becomes harder to ascertain what a given
variable’s type is.</span><span> Some coding practices, like functional programming, recommend never reassigning
a variable.</span><span> In Java this is done with the final keyword.</span><span> Python does not have
a final keyword and it would be against its philosophy anyway.</span><span class="highlight"> However, it may
be a good discipline to avoid assigning to a variable more than once, and it
helps in grasping the concept of mutable and immutable types.</span><span> Mutable and immutable types¶
Python has two kinds of built-in or user-defined types.</span><span> Mutable types are those that allow in-place modification of the content.</span><span class="highlight"> Typical
mutables are lists and dictionaries: All lists have mutating methods, like
list.append() or list.pop(), and can be modified in place.</span><span> The same goes for dictionaries.</span><span> Immutable types provide no method for changing their content.</span><span class="highlight"> For instance, the
variable x set to the integer 6 has no “increment” method.</span><span class="highlight"> If you want to
compute x + 1, you have to create another integer and give it a name.</span><span class="highlight"> my_list = [1, 2, 3]
my_list[0] = 4
print my_list  # [4, 2, 3] &lt;- The same list has changed

x = 6
x = x + 1  # The new x is another object


One consequence of this difference in behavior is that mutable
types are not “stable”, and therefore cannot be used as dictionary
keys.</span><span class="highlight"> Using properly mutable types for things that are mutable in nature
and immutable types for things that are fixed in nature
helps to clarify the intent of the code.</span><span class="highlight"> For example, the immutable equivalent of a list is the tuple, created
with (1, 2).</span><span class="highlight"> This tuple is a pair that cannot be changed in-place,
and can be used as a key for a dictionary.</span><span> One peculiarity of Python that can surprise beginners is that
strings are immutable.</span><span class="highlight"> This means that when constructing a string from
its parts, appending each part to the string is inefficient because
the entirety of the string is copied on each append.</span><span class="highlight"> Instead, it is much more efficient to accumulate the parts in a list,
which is mutable, and then glue (join) the parts together when the
full string is needed.</span><span> List comprehensions are usually the fastest and
most idiomatic way to do this.</span><span> Bad
# create a concatenated string from 0 to 19 (e.g.</span><span class="highlight"> &quot;012..1819&quot;)
nums = &quot;&quot;
for n in range(20):
    nums += str(n)   # slow and inefficient
print nums


Better
# create a concatenated string from 0 to 19 (e.g.</span><span class="highlight"> &quot;012..1819&quot;)
nums = []
for n in range(20):
    nums.append(str(n))
print &quot;&quot;.join(nums)  # much more efficient


Best
# create a concatenated string from 0 to 19 (e.g.</span><span class="highlight"> &quot;012..1819&quot;)
nums = [str(n) for n in range(20)]
print &quot;&quot;.join(nums)


One final thing to mention about strings is that using join() is not always
best.</span><span class="highlight"> In the instances where you are creating a new string from a pre-determined
number of strings, using the addition operator is actually faster, but in cases
like above or in cases where you are adding to an existing string, using
join() should be your preferred method.</span><span class="highlight"> foo = &#x27;foo&#x27;
bar = &#x27;bar&#x27;

foobar = foo + bar  # This is good
foo += &#x27;ooo&#x27;  # This is bad, instead you should do:
foo = &#x27;&#x27;.join([foo, &#x27;ooo&#x27;])



Note
You can also use the % formatting operator
to concatenate a pre-determined number of strings besides str.join()
and +.</span><span class="highlight"> However, PEP 3101 discourages the usage of the % operator
in favor of the str.format() method.</span><span class="highlight"> foo = &#x27;foo&#x27;
bar = &#x27;bar&#x27;

foobar = &#x27;%s%s&#x27; % (foo, bar) # It is OK
foobar = &#x27;{0}{1}&#x27;.format(foo, bar) # It is better
foobar = &#x27;{foo}{bar}&#x27;.format(foo=foo, bar=bar) # It is best




Vendorizing Dependencies¶


Runners¶


Further Reading¶

http://docs.python.org/3/library/
https://diveintopython3.net/</span>
        </div>
    </body>
</html>